{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Intro"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is following a tutorial from [machine learning mastery](https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/) just to get familiar with things\n",
    "\n",
    "I am going to dump a lot of the tips I found useful into this notebook.\n",
    "There will also be a lot of links to the authors other works."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Breakdown of the data\n",
    "\n",
    "# Input Variables (X):\n",
    "# 1. Number of times pregnant\n",
    "# 2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "# 3. Diastolic blood pressure (mm Hg)\n",
    "# 4. Triceps skin fold thickness (mm)\n",
    "# 5. 2-Hour serum insulin (mu U/ml)\n",
    "# 6. Body mass index (weight in kg/(height in m)^2)\n",
    "# 7. Diabetes pedigree function\n",
    "# 8. Age (years)\n",
    "\n",
    "# Output Variables (y):\n",
    "# 1. Class variable (0 or 1)\n",
    "\n",
    "# The turoial wants us to use the numpy loadtxt\n",
    "dataset = loadtxt(\"pima-indians-diabetes.csv\", delimiter=',')\n",
    "X = dataset[:, 0:8]\n",
    "y = dataset[:, 8]\n",
    "\n",
    "# Here is the equivalent in pandas - just to prove a point\n",
    "# import pandas as pd\n",
    "# pandas_dataset = pd.read_csv(\"pima-indians-diabetes.csv\", delimiter=',', header=None)\n",
    "# pandas_X = pandas_dataset.loc[:, 0:7]\n",
    "# pandas_y = pandas_dataset.loc[:, 8]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define the Keras Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first thing to get right is to ensure the input layer has the right number of input features.\n",
    "This can be specified when creating the first layer with the input_dim argument and setting it to 8 for the 8 input variables.\n",
    "The tutorial asks how to determine the number of nodes in each layer, then links to [another of their posts](https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/)\n",
    "\n",
    "It used to be the case that Sigmoid and Tanh activation functions were preferred for all layers.\n",
    "These days, better performance is achieved using the ReLU activation function.\n",
    "We use a sigmoid on the output layer to ensure our network output is between 0 and 1 and easy to map to either a probability of class 1 or snap to a hard classification of either class with a default threshold of 0.5."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Note***,\n",
    "the most confusing thing here is that the shape of the input to the model is defined as an argument on the first hidden layer.\n",
    "This means that the line of code that adds the first Dense layer is doing 2 things, defining the input or visible layer and the first hidden layer."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compile the Keras Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When compiling, we must specify some additional properties required when training the network.\n",
    "Remember training a network means finding the best set of weights to map inputs to outputs in our dataset.\n",
    "\n",
    "We must specify the **loss function** to use to evaluate a set of weights, the optimizer is used to search through different weights for the network and any optional metrics we would like to collect and report during training.\n",
    "\n",
    "[How to Choose Loss Functions When Training Deep Learning Neural Networks](https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/)\n",
    "\n",
    "We will define the **optimizer** as the efficient stochastic gradient descent algorithm “adam“.\n",
    "This is a popular version of gradient descent because it automatically tunes itself and gives good results in a wide range of problems.\n",
    "[Gentle Introduction to the Adam Optimization Algorithm for Deep Learning](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)\n",
    "\n",
    "Finally, because it is a classification problem, we will collect and report the classification accuracy, defined via the **metrics** argument"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fit the Keras Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training occurs over epochs and each epoch is split into batches.\n",
    "\n",
    "***Epoch***: One pass through all of the rows in the training dataset.\n",
    "***Batch***: One or more samples considered by the model within an epoch before weights are updated.\n",
    "\n",
    "One epoch is comprised of one or more batches, based on the chosen batch size and the model is fit for many epochs.\n",
    "\n",
    "These configurations can be chosen experimentally by trial and error.\n",
    "We want to train the model enough so that it learns a good (or good enough) mapping of rows of input data to the output classification.\n",
    "The model will always have some error, but the amount of error will level out after some point for a given model configuration.\n",
    "\n",
    "*This is called **model convergence**.*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(X, y, epochs=150, batch_size=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Note**:\n",
    "Neural nets require ALL inputs to be numeric, make sure that you do some form of encoding on your categoricals before throwing your dataset at the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate the Keras Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So the tutorial was super lazy here and just evaluated the data on the same dataset it trained on.\n",
    "**DO NOT DO THIS IN THE REAL WORLD**\n",
    "To their credit they did say in a real example you should split into train and test sets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, accuracy = model.evaluate(X, y)\n",
    "print(f\"Accuracy: {accuracy * 100.0:.2f} %\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = model.predict(X)\n",
    "\n",
    "# If instead you want your predictions as labels\n",
    "threshold = 0.5\n",
    "predictions_crisp = (model.predict(X) > threshold).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions_crisp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"The single model gives us an accuracy of: {100.0 * np.mean(predictions_crisp == y.astype(int)):.2f} %\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# My improvements / experiments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Due to the stochastic nature of backpropagation we can train the model multiple times and it will be slightly different.\n",
    "This can be advantageous as you can do similar things to ensemble machine learning and stack the outcomes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "# Generate multiple models\n",
    "for i in range(0, 5):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation=\"relu\"))\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    model.fit(X, y, epochs=150, batch_size=10, verbose=0)\n",
    "\n",
    "    _, accuracy = model.evaluate(X, y)\n",
    "    print(f\"Model {i} has accuracy: {accuracy * 100.0:.2f} %\")\n",
    "    key = f\"model_{i}\"\n",
    "    models[key] = model\n",
    "    predictions[key] = (model.predict(X) > threshold).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "\n",
    "group_prediction = []\n",
    "for i in range(0, len(X)):\n",
    "    group_prediction.append(mode([predictions[key][i][0] for key in predictions.keys()]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Group think gives us an accuracy of: {100.0 * np.mean(group_prediction == y.astype(int)):.2f} %\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "By taking the **mode prediction** of a bunch of models for each data point we can hopefully make a model that is better than average\n",
    "As you can see, if we had just trained a single model we might have been unlucky and got one of the under performing models\n",
    "\n",
    "In essence this is what a lot of fancy research neural nets are doing.\n",
    "By making a swarm of slightly different models that can cover each others weaknesses we end up with a prevailing group model that makes on average better choices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}